{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "emerging-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "#from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dried-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open catalogue\n",
    "df = pd.read_csv('/home/data/ReAnalysis/ERA5/Storm_analysis/NAECv1/NAEC_1979_2020_v1.csv')\n",
    "\n",
    "# open netcdf mask file\n",
    "file = '/pampa/picart/Masks/mask_GEM5_ERA5grid'\n",
    "data = xr.open_dataset(file)\n",
    "\n",
    "# export netcdf to dataframe and drop index\n",
    "mk = data.to_dataframe().reset_index()\n",
    "\n",
    "# Only keep grid points coordinates that are within CRCM6 domain\n",
    "mk = mk.loc[mk.HU == True]\n",
    "\n",
    "# open crcm6 boundary layer \n",
    "bnd = pd.read_csv('/pampa/cloutier/outline_crcm6_domain.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "documented-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chen filtre les ETC qui sont pendant au moins 24h CONSÉCUTIVES dans le domaine et dont le centre est\n",
    "# à une distance minimale de 5° du bord du domaine de CRCM6.\n",
    "\n",
    "# on doit donc déterminer une fonction qui calcule la distance entre un point de grille et le bord du \n",
    "# domaine de CRCM6\n",
    "\n",
    "# Il faut que le point de grille ait une valeur HU == True et qu'il soit è une distance minimale de 5° de \n",
    "# tous les points de grille qui tracent la limite \n",
    "mk = mk.rename(columns={'lat' : 'latitude', 'lon' : 'longitude'})\n",
    "merge = df.merge(mk, how='left', on=['latitude', 'longitude'])\n",
    "merge = merge.fillna(value = False)\n",
    "df24_consec = pd.DataFrame(columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "indie-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui détermine si le point donné dans le catalogue est à une distance \n",
    "# minimale de tous les points de grille du frame du domaine de crcm6 de 5°\n",
    "\n",
    "def get_distance(latS, lonS, bnd) :\n",
    "    dist_cond = True\n",
    "\n",
    "    for _, row2 in bnd.iterrows():\n",
    "        latD = row2['lat']\n",
    "        lonD = row2['lon']\n",
    "        dist = ((latS-latD)**2 + (lonS - lonD)**2)**0.5\n",
    "        \n",
    "        if dist < 5 : \n",
    "            dist_min = False\n",
    "            break\n",
    "            \n",
    "    return dist_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "friendly-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year in process :  1979010204\n",
      "Storm :  1\n",
      "Year in process :  1979010218\n",
      "Storm :  3\n",
      "Year in process :  1979010822\n",
      "Storm :  12\n",
      "Year in process :  1979011015\n",
      "Storm :  13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-7be721a50260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# If the grid point is in the subdomain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhu\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mdist_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlonS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# No need to put and HU == True in the next if condition, because if dist_cond = true,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-7cfef3af5f62>\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(latS, lonS, bnd)\u001b[0m\n\u001b[1;32m     81\u001b[0m                        (bnd['lon'] < lonS - 6) | (bnd['lon'] > lonS + 6)]\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbnd_filt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mlatD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlonD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfrom_array\u001b[0;34m(cls, array, index)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mConstructor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myet\u001b[0m \u001b[0ma\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \"\"\"\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_block_type\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   2686\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetime64tz_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeTZDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0;31m# https://github.com/pandas-dev/pandas/issues/22960\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;31m# avoid passing data to `construct_from_string`. This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate through each storm\n",
    "for storm_id in merge['storm'].unique():\n",
    "    storm_data = merge[merge['storm'] == storm_id].copy()\n",
    "    count = 0\n",
    "   \n",
    "    # Iterate through each grid point\n",
    "    for _, row in storm_data.iterrows() :\n",
    "        dist_cond = False\n",
    "        hu = row['HU']\n",
    "        latS = row['latitude']\n",
    "        lonS = row['longitude']\n",
    "        \n",
    "        # If the grid point is in the subdomain \n",
    "        if hu : \n",
    "            dist_cond = get_distance(latS, lonS, bnd)\n",
    "    \n",
    "        # No need to put and HU == True in the next if condition, because if dist_cond = true, \n",
    "        # it means that the if hu conditions was respected (dist_cond is reset to false for each \n",
    "        # grid point iteration )\n",
    "        if dist_cond : \n",
    "            count += 1\n",
    "\n",
    "        if hu == False and count >= 24 :\n",
    "            break\n",
    "\n",
    "        if hu == False and count < 24 :\n",
    "            count = 0\n",
    "\n",
    "    if count >= 24 : \n",
    "        df24_consec = df24_consec.append(storm_data)\n",
    "        print('Year in process : ', df24_consec['datetime'].iloc[-1])\n",
    "        print('Storm : ', df24_consec['storm'].iloc[-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "passive-sauce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        mk_filtered = mk.loc[(mk['latitude'] <= latS - 5) | (mk['latitude'] >= latS + 5) |\n",
    "                             (mk['longitude'] <= lonS - 5) | (mk['longitude'] >= lonS + 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-criticism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "manufactured-county",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "24\n",
      "Year in process :  1979010204\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "    Maxine Cloutier-Gervais\n",
    "\n",
    "Created : \n",
    "\n",
    "    June 7th, 2023\n",
    "\n",
    "Info : \n",
    "    \n",
    "    This code creates and filters, a file that contains ETC that were active for 24 consecutives \n",
    "    hours or more in the crcm6 domain.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def open_cat_mask(cat_in, bnd_in, mask_in) : \n",
    "\n",
    "    \"\"\"\n",
    "    Open NAEC catalogue, boundary file  and transform netCDF mask into dataframe \n",
    "\n",
    "    Parameters  : \n",
    "        cat_in  : path of the catalogue csv file\n",
    "        mask_in : path of the mask netCDF file\n",
    "        bnd_in  : path of the csv file that defines the boundary grid points\n",
    "                  of CRCM6 domain\n",
    "                    \n",
    "    Returns : \n",
    "        cat : Dataframe containing NAEC catalogue data\n",
    "        mk  : Dataframe containing mask data\n",
    "        bnd : Dataframe containing boundary grid points \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1 : Open catalogue and boundary csv file\n",
    "    print('lecture cat...')\n",
    "    cat = pd.read_csv(cat_in)\n",
    "    print('lecture bnd...')\n",
    "    bnd = pd.read_csv(bnd_in, index_col = 0)\n",
    "\n",
    "    # Step 2 : Open mask netCDF file and convert into dataframe\n",
    "    print('lecture mask...')\n",
    "    mk = xr.open_dataset(mask_in)\n",
    "    mk = mk.to_dataframe()\n",
    "\n",
    "    # Step 3 :  Drop index lat lon, but keep columns\n",
    "    mk = mk.reset_index()\n",
    "\n",
    "    # Step 4 : Rename lat & lon columns for latitude & longitude\n",
    "    mk = mk.rename(columns={'lat' : 'latitude', 'lon' : 'longitude'})\n",
    "\n",
    "    return cat, bnd, mk\n",
    "\n",
    "\n",
    "def get_distance(latS, lonS, bnd) : \n",
    "\n",
    "    \"\"\"\n",
    "    Determine if a given grid point is at a minimal distance of 5deg from\n",
    "    all CRCM6 boundary grid point domain\n",
    "\n",
    "    Paramters : \n",
    "        latS  : Latitude of the catalogue grid point\n",
    "        lonS  : Longitude of the catalogue grid point\n",
    "        bnd   : Dataframe containing boundary grid points\n",
    "\n",
    "    Returns       : \n",
    "        dist_cond : True if all grid points are within a minimal distance of 5deg\n",
    "                    from all boundary layer grid points and False if not.\n",
    "    \"\"\"\n",
    "\n",
    "    dist_cond = True\n",
    "    \n",
    "    # filter out boundary grid points to restrict search\n",
    "    bnd_filt = bnd.loc[(bnd['lat'] < latS - 6) | (bnd['lat'] > latS + 6) |\n",
    "                       (bnd['lon'] < lonS - 6) | (bnd['lon'] > lonS + 6)]\n",
    "    \n",
    "    for _, row1 in bnd_filt.iterrows():\n",
    "        latD = row1['lat']\n",
    "        lonD = row1['lon']\n",
    "        dist = ((latS-latD)**2 + (lonS - lonD)**2)**0.5\n",
    "        \n",
    "        if dist < 5 : \n",
    "            dist_min = False\n",
    "            break\n",
    "            \n",
    "    return dist_cond\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_season(df, output_file) : \n",
    "\n",
    "    \"\"\"\n",
    "    Add a column called 'season' in df24 that gives the season in which the ETC occured. \n",
    "    If the ETC occured in two or more season, the chosen season will be the one in which \n",
    "    the ETC has the most grid point\n",
    "\n",
    "    DJF : December, January & November\n",
    "    MAM : March, April & May\n",
    "    JJA : June, July & April\n",
    "    SON : September, October and December\n",
    "    \n",
    "    Parameters : \n",
    "        df (dataframe) : Dataframe to which we want to add the season column\n",
    "\n",
    "    returns : \n",
    "        df_new : \n",
    "    \"\"\"\n",
    "\n",
    "    seasons = { 'SON': [9, 10, 11], 'DJF': [12, 1, 2], 'MAM': [3, 4, 5], 'JJA': [6, 7, 8] }\n",
    "\n",
    "    # Step 1 : Add 'month' column in dataframe \n",
    "\n",
    "    df['month'] = (df.datetime // 10000) % 100\n",
    "\n",
    "    # Step 2 : Group the storms by their ID and count the number of grid point \n",
    "    #          in each month\n",
    "\n",
    "    storm_seasons = df.groupby(['storm', 'month']).size().unstack().fillna(0)\n",
    "\n",
    "    # Step 3 : Determine the month with the maximum grid points for each storm\n",
    "\n",
    "    storm_seasons['season'] = storm_seasons.idxmax(axis=1)\n",
    "    \n",
    "    # Step 4 : Transform month number into season\n",
    "    \n",
    "    storm_seasons['season'] = storm_seasons['season'].map(\n",
    "    lambda month: next((season for season, months in seasons.items() if month in months), None)\n",
    "    )\n",
    "    \n",
    "    # Step 5 : Merge the season column into original dataframe\n",
    "    \n",
    "    df_new = df.merge(storm_seasons['season'], on='storm', how='left')\n",
    "\n",
    "    # Step 6 : Delete month column\n",
    "\n",
    "    df_new = df_new.drop(['month'], axis = 1)\n",
    "    \n",
    "    # Step 7 : move season column next to datetime (TODO)\n",
    "    \n",
    "    #df_new.insert(3, 'season', df_new.pop('season'))\n",
    "\n",
    "    return df_new\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" MAIN PROGRAM \"\"\"\n",
    "\n",
    "\n",
    "# Step 1 : Open catalogue, boundary catalogue and mask\n",
    "cat_in = ('/home/data/ReAnalysis/ERA5/Storm_analysis/NAECv1/NAEC_1979_2020_v1.csv')\n",
    "bnd_in = ('/pampa/cloutier/outline_crcm6_domain.csv')\n",
    "mask_in = ('/pampa/picart/Masks/mask_GEM5_ERA5grid')\n",
    "\n",
    "#cat, bnd, mk = open_cat_mask(cat_in, bnd_in, mask_in)\n",
    "\n",
    "# Step 2 : Merge cat and mask to add HU column in cat\n",
    "#cat = cat.loc[(cat.storm == 3) | (cat.storm == 1)]\n",
    "merge = cat.merge(mk, how='left', on=['latitude', 'longitude'])\n",
    "merge = merge.fillna(value = False)\n",
    "\n",
    "# Step 3 : Initialize empty dataframe that will contain the final result\n",
    "\n",
    "df24 = pd.DataFrame(columns = cat.columns)\n",
    "\n",
    "# Step 4 : Filter catalogue data\n",
    "\n",
    "# Iterate through each storm \n",
    "for storm_id in merge['storm'].unique():\n",
    "    storm_data = merge[merge['storm'] == storm_id].copy() # copy of merge for the given storm\n",
    "    count = 0 # lifetime count\n",
    "    stInDom=[]\n",
    "\n",
    "    # Iterate through each grid point of the storm\n",
    "    for _, row in storm_data.iterrows() : \n",
    "        hu = row['HU']\n",
    "        cond = False\n",
    "        latS = row['latitude']\n",
    "        lonS= row['longitude']\n",
    "        \n",
    "        # check if storm center is within subdomain and at a 5° minimal \n",
    "        # distance from boundaries\n",
    "        if hu : \n",
    "            #print('check distance ...')\n",
    "            cond = get_distance(latS, lonS, bnd) \n",
    "        stInDom.append(cond)\n",
    "    \n",
    "    # add a new column that determines if each storm center agrees or not with the above condition\n",
    "    #print('adding StInDom in storm_data ...')\n",
    "    storm_data['StInDom'] = stInDom\n",
    "    n = 23\n",
    "    # exclude the last 23 lines in the search\n",
    "    #storm_data_rows = storm_data.head(len(storm_data) - n)\n",
    "    storm_data_rows = storm_data.iloc[:-n]\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    #print('second for loop : ', row['storm'])\n",
    "    for idx, row in storm_data_rows.iterrows() :\n",
    "        print(row['StInDom'])\n",
    "        if row['StInDom'] == True : \n",
    "            #print('Initializing count to one')\n",
    "            count = 1\n",
    "            \n",
    "            # keep iterating for the next 23 grid points\n",
    "            for _, row in islice(storm_data.iterrows(), idx, idx+23) : \n",
    "                if row['StInDom'] : \n",
    "                    count += 1\n",
    "                    print(count)\n",
    "                \n",
    "                else :  \n",
    "                    #print(row['StInDom'], 'storm not in domain')\n",
    "                    break\n",
    "            \n",
    "            if count >= 24 : \n",
    "                break\n",
    "                \n",
    "    print(count)                           \n",
    "    if count >= 24 :\n",
    "        df24 = df24.append(storm_data)\n",
    "        print('Year in process : ', df24['datetime'].iloc[-1])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "familiar-minutes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print(stInDom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "judicial-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "    Maxine Cloutier-Gervais\n",
    "\n",
    "Created : \n",
    "\n",
    "    June 7th, 2023\n",
    "\n",
    "Info : \n",
    "    \n",
    "    This code creates and filters, a file that contains ETC that were active for 24 consecutives \n",
    "    hours or more in the crcm6 domain.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def open_cat_mask(cat_in, bnd_in, mask_in) : \n",
    "\n",
    "    \"\"\"\n",
    "    Open NAEC catalogue, boundary file  and transform netCDF mask into dataframe \n",
    "\n",
    "    Parameters  : \n",
    "        cat_in  : path of the catalogue csv file\n",
    "        mask_in : path of the mask netCDF file\n",
    "        bnd_in  : path of the csv file that defines the boundary grid pointsd\n",
    "                  of CRCM6 domain\n",
    "                    \n",
    "    Returns : \n",
    "        cat : Dataframe containing NAEC catalogue data\n",
    "        mk  : Dataframe containing mask data\n",
    "        bnd : Dataframe containing boundary grid points \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1 : Open catalogue and boundary csv file\n",
    "    print('lecture cat...')\n",
    "    cat = pd.read_csv(cat_in)\n",
    "    print('lecture bnd...')\n",
    "    bnd = pd.read_csv(bnd_in, index_col = 0)\n",
    "\n",
    "    # Step 2 : Open mask netCDF file and convert into dataframe\n",
    "    print('lecture mask...')\n",
    "    mk = xr.open_dataset(mask_in)\n",
    "    mk = mk.to_dataframe()\n",
    "\n",
    "    # Step 3 :  Drop index lat lon, but keep columns\n",
    "    mk = mk.reset_index()\n",
    "\n",
    "    # Step 4 : Rename lat & lon columns for latitude & longitude\n",
    "    mk = mk.rename(columns={'lat' : 'latitude', 'lon' : 'longitude'})\n",
    "\n",
    "    return cat, bnd, mk\n",
    "\n",
    "\n",
    "def get_distance(latS, lonS, bnd) : \n",
    "\n",
    "    \"\"\"\n",
    "    Determine if a given grid point is at a minimal distance of 5deg from\n",
    "    all CRCM6 boundary grid point domain\n",
    "\n",
    "    Paramters : \n",
    "        latS  : Latitude of the catalogue grid point\n",
    "        lonS  : Longitude of the catalogue grid point\n",
    "        bnd   : Dataframe containing boundary grid points\n",
    "\n",
    "    Returns       : \n",
    "        dist_cond : True if all grid points are within a minimal distance of 5deg\n",
    "                    from all boundary layer grid points and False if not.\n",
    "    \"\"\"\n",
    "\n",
    "    dist_cond = True\n",
    "    \n",
    "    # filter out boundary grid points to restrict search\n",
    "    bnd_filt = bnd.loc[(bnd['lat'] < latS - 6) | (bnd['lat'] > latS + 6) |\n",
    "                       (bnd['lon'] < lonS - 6) | (bnd['lon'] > lonS + 6)]\n",
    "    \n",
    "    for _, row1 in bnd_filt.iterrows():\n",
    "        latD = row1['lat']\n",
    "        lonD = row1['lon']\n",
    "        dist = ((latS-latD)**2 + (lonS - lonD)**2)**0.5\n",
    "        \n",
    "        if dist < 5 : \n",
    "            dist_min = False\n",
    "            break\n",
    "            \n",
    "    return dist_cond\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_season(df, output_file) : \n",
    "\n",
    "    \"\"\"\n",
    "    Add a column called 'season' in df24 that gives the season in which the ETC occured. \n",
    "    If the ETC occured in two or more season, the chosen season will be the one in which \n",
    "    the ETC has the most grid point\n",
    "\n",
    "    DJF : December, January & November\n",
    "    MAM : March, April & May\n",
    "    JJA : June, July & April\n",
    "    SON : September, October and December\n",
    "    \n",
    "    Parameters : \n",
    "        df (dataframe) : Dataframe to which we want to add the season column\n",
    "\n",
    "    returns : \n",
    "        df_new : \n",
    "    \"\"\"\n",
    "\n",
    "    seasons = { 'SON': [9, 10, 11], 'DJF': [12, 1, 2], 'MAM': [3, 4, 5], 'JJA': [6, 7, 8] }\n",
    "\n",
    "    # Step 1 : Add 'month' column in dataframe \n",
    "\n",
    "    df['month'] = (df.datetime // 10000) % 100\n",
    "\n",
    "    # Step 2 : Group the storms by their ID and count the number of grid point \n",
    "    #          in each month\n",
    "\n",
    "    storm_seasons = df.groupby(['storm', 'month']).size().unstack().fillna(0)\n",
    "\n",
    "    # Step 3 : Determine the month with the maximum grid points for each storm\n",
    "\n",
    "    storm_seasons['season'] = storm_seasons.idxmax(axis=1)\n",
    "    \n",
    "    # Step 4 : Transform month number into season\n",
    "    \n",
    "    storm_seasons['season'] = storm_seasons['season'].map(\n",
    "    lambda month: next((season for season, months in seasons.items() if month in months), None)\n",
    "    )\n",
    "    \n",
    "    # Step 5 : Merge the season column into original dataframe\n",
    "    \n",
    "    df_new = df.merge(storm_seasons['season'], on='storm', how='left')\n",
    "\n",
    "    # Step 6 : Delete month column\n",
    "\n",
    "    df_new = df_new.drop(['month'], axis = 1)\n",
    "    \n",
    "    # Step 7 : move season column next to datetime (TODO)\n",
    "    \n",
    "    #df_new.insert(3, 'season', df_new.pop('season'))\n",
    "\n",
    "    return df_new\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" MAIN PROGRAM \"\"\"\n",
    "\n",
    "\n",
    "# Step 1 : Open catalogue, boundary catalogue and mask\n",
    "cat_in = ('/home/data/ReAnalysis/ERA5/Storm_analysis/NAECv1/NAEC_1979_2020_v1.csv')\n",
    "bnd_in = ('/pampa/cloutier/outline_crcm6_domain.csv')\n",
    "mask_in = ('/pampa/picart/Masks/mask_GEM5_ERA5grid')\n",
    "\n",
    "#cat, bnd, mk = open_cat_mask(cat_in, bnd_in, mask_in)\n",
    "\n",
    "# Step 2 : Merge cat and mask to add HU column in cat\n",
    "#cat = cat.loc[(cat.storm == 3) | (cat.storm == 1)]\n",
    "merge = cat.merge(mk, how='left', on=['latitude', 'longitude'])\n",
    "merge = merge.fillna(value = False)\n",
    "\n",
    "# Step 3 : Initialize empty dataframe that will contain the final result\n",
    "\n",
    "df24 = pd.DataFrame(columns = cat.columns)\n",
    "\n",
    "# Step 4 : Filter catalogue data\n",
    "\n",
    "# Iterate through each storm \n",
    "for storm_id in merge['storm'].unique():\n",
    "    storm_data = merge[merge['storm'] == storm_id].copy() # copy of merge for the given storm\n",
    "    count = 0 # lifetime count\n",
    "    stInDom=[]\n",
    "\n",
    "    # Iterate through each grid point of the storm\n",
    "    for _, row in storm_data.iterrows() : \n",
    "        hu = row['HU']\n",
    "        cond = False\n",
    "        latS = row['latitude']\n",
    "        lonS= row['longitude']\n",
    "        \n",
    "        # check if storm center is within subdomain and at a 5° minimal \n",
    "        # distance from boundaries\n",
    "        if hu : \n",
    "            #print('check distance ...')\n",
    "            cond = get_distance(latS, lonS, bnd) \n",
    "        stInDom.append(cond)\n",
    "    \n",
    "    # add a new column that determines if each storm center agrees or not with the above condition\n",
    "    #print('adding StInDom in storm_data ...')\n",
    "    storm_data['StInDom'] = stInDom\n",
    "    n = 23\n",
    "    # exclude the last 23 lines in the search\n",
    "    #storm_data_rows = storm_data.head(len(storm_data) - n)\n",
    "    storm_data_rows = storm_data.iloc[:-n]\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    #print('second for loop : ', row['storm'])\n",
    "    for idx, row in storm_data_rows.iterrows():\n",
    "        if row['StInDom'] == True:\n",
    "            count = 1\n",
    "        \n",
    "        # Iterate through the next 23 rows or until the end of the storm_data\n",
    "            for i in range(idx + 1, min(idx + 24, len(storm_data))):\n",
    "                if storm_data.loc[i, 'StInDom'] == True:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "    print(count)\n",
    "#         if count >= 24:\n",
    "#             df24 = df24.append(storm_data)\n",
    "#             print('Year in process:', df24['datetime'].iloc[-1])\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "obvious-rough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lecture cat...\n",
      "lecture bnd...\n",
      "lecture mask...\n",
      "storm ...  1\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Year in process: 1979010204\n",
      "storm ...  2\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "storm ...  3\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Year in process: 1979010218\n"
     ]
    }
   ],
   "source": [
    "# Step 1 : Open catalogue, boundary catalogue and mask\n",
    "cat_in = ('/home/data/ReAnalysis/ERA5/Storm_analysis/NAECv1/NAEC_1979_2020_v1.csv')\n",
    "bnd_in = ('/pampa/cloutier/outline_crcm6_domain.csv')\n",
    "mask_in = ('/pampa/picart/Masks/mask_GEM5_ERA5grid')\n",
    "\n",
    "cat, bnd, mk = open_cat_mask(cat_in, bnd_in, mask_in)\n",
    "\n",
    "# Step 2 : Merge cat and mask to add HU column in cat\n",
    "#cat = cat.loc[(cat.storm == 1) | (cat.storm == 2) | (cat.storm == 3)]\n",
    "merge = cat.merge(mk, how='left', on=['latitude', 'longitude'])\n",
    "merge = merge.fillna(value = False)\n",
    "\n",
    "# Step 3 : Initialize empty dataframe that will contain the final result\n",
    "\n",
    "df24 = pd.DataFrame(columns = cat.columns)\n",
    "\n",
    "for storm_id, group in merge.groupby('storm'):\n",
    "    print('storm ... ', storm_id)\n",
    "    stInDom = group['HU'] & group.apply(lambda row: get_distance(row['latitude'], row['longitude'], bnd), axis=1)\n",
    "    count = 0\n",
    "    for value in stInDom:\n",
    "        print(value)\n",
    "        if value:\n",
    "            count += 1\n",
    "            if count >= 24:\n",
    "                df24 = df24.append(group)\n",
    "                print('Year in process:', df24['datetime'].iloc[-1])\n",
    "                break\n",
    "        else:\n",
    "            count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-wright",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
