{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "designed-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "least-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open catalogue dataset\n",
    "df = pd.read_csv('/home/data/ReAnalysis/ERA5/Storm_analysis/NAECv1/NAEC_1979_2020_v1.csv')\n",
    "\n",
    "# open netcdf mask file\n",
    "file = '/pampa/picart/Masks/mask_GEM5_ERA5grid'\n",
    "data = xr.open_dataset(file)\n",
    "\n",
    "# export netcdf to dataframe\n",
    "mask = data.to_dataframe()\n",
    "\n",
    "# drop index lat lon, but keep columns\n",
    "mask = mask.reset_index()\n",
    "\n",
    "# rename lat & lon columns as latitude & longitude\n",
    "mask = mask.rename(columns={'lat' : 'latitude', 'lon' : 'longitude'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-earthquake",
   "metadata": {},
   "source": [
    "### Keep storms that were active in NNA for at least 24 CONSECUTIVES hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "divine-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to store the storms that were active \n",
    "# for at least 24 CONSECUTIVES hours in the CRCM6 domain\n",
    "\n",
    "merge = df.merge(mask, how='left', on=['latitude', 'longitude'])\n",
    "df24_consec = pd.DataFrame(columns=df.columns)\n",
    "#print(df24)# \n",
    "\n",
    "# make sure that df24 and mask have the same number of coords that are true\n",
    "\n",
    "# true_df = (df24.loc[(df24.HU == True)])\n",
    "# coord_count = true_df.groupby(['latitude', 'longitude']).count()\n",
    "# print(len(coord_count))\n",
    "# print(len(mask.loc[mask.HU == True]))\n",
    "\n",
    "# replace NaN with False\n",
    "merge = merge.fillna(value=False)\n",
    "\n",
    "# iterate through each storm\n",
    "for storm_id in merge['storm'].unique():\n",
    "    storm_data = merge[merge['storm'] == storm_id].copy()\n",
    "    count_domain = 0\n",
    "    nna_lifetime = []\n",
    "\n",
    "    for _, row in storm_data.iterrows() :\n",
    "        #print(row['storm'], row['latitude'], row['longitude'], row['HU'], count_domain)\n",
    "        if row['HU'] == True :\n",
    "            count_domain += 1\n",
    "        # if we have count > 24 and encounter a False value, exit 'for'\n",
    "        # statement\n",
    "        if row['HU'] == False and count_domain >= 24 :  \n",
    "            break\n",
    "        # if we don't have count > 24 yet but we encounter a False value, \n",
    "        # reset count and go to the next grid point \n",
    "        if row['HU'] == False and count_domain < 24 : \n",
    "            count_domain = 0\n",
    "            continue\n",
    "\n",
    "    if count_domain >= 24 : \n",
    "        df24_consec = df24_consec.append(storm_data)\n",
    "        # check where the code is at \n",
    "        print(df24_consec['datetime'].iloc[-1])\n",
    "\n",
    "print(len(df24_consec.groupby(['storm']).count()))\n",
    "df24_consec.to_csv('/pampa/cloutier/df24_consec.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-paintball",
   "metadata": {},
   "source": [
    "### Keep storms that were active in NNA for at least 24 hours IN TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "sacred-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to store the storms that were active \n",
    "# for more than 24h IN TOTAL (not consecutively) the CRCM6 domain\n",
    "\n",
    "merge = df.merge(mask, how='left', on=['latitude', 'longitude'])\n",
    "df24_noconsec = pd.DataFrame(columns=df.columns)\n",
    "#print(df24)\n",
    "\n",
    "# make sure that df24 and mask have the same number of coords that are true\n",
    "\n",
    "# true_df = (df24.loc[(df24.HU == True)])\n",
    "# coord_count = true_df.groupby(['latitude', 'longitude']).count()\n",
    "# print(len(coord_count))\n",
    "# print(len(mask.loc[mask.HU == True]))\n",
    "\n",
    "# replace NaN with False\n",
    "merge = merge.fillna(value=False)\n",
    "\n",
    "# iterate through each storm\n",
    "for storm_id in merge['storm'].unique():\n",
    "    storm_data = merge[merge['storm'] == storm_id].copy()\n",
    "    count_domain = 0\n",
    "    \n",
    "    group = storm_data.groupby(['storm','HU']).size()\n",
    "    # Calculate the sum of 'HU' values that are True\n",
    "    hu_sum = storm_data.loc[storm_data['HU'] == True, 'HU'].sum()  \n",
    "\n",
    "    if hu_sum >= 24 : \n",
    "        df24_noconsec = df24_noconsec.append(storm_data)\n",
    "        # check where the code is at \n",
    "        print(df24_noconsec['datetime'].iloc[-1])\n",
    "\n",
    "print(len(df24_noconsec.groupby(['storm']).count()))\n",
    "df24_noconsec.to_csv('/pampa/cloutier/df24_no_consec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "leading-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# storm for 24h consecutive :  6636\n",
      "# storm for 24h NOT consecutive :  6708\n"
     ]
    }
   ],
   "source": [
    "print('# storm for 24h consecutive : ', len(df24_consec.groupby(['storm']).count()))\n",
    "print('# storm for 24h NOT consecutive : ',len(df24_noconsec.groupby(['storm']).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-specification",
   "metadata": {},
   "source": [
    "### Extract ETC DataFrame for specific season\n",
    "OLD VERSION NOT WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "extraordinary-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract month from datetime with (df.datetime//10000)%100 and apply conditionnal selection according the the needed months\n",
    "\n",
    "#    def get_season\n",
    "#    ARGS m1, m2, m3 (int) : The 3 wanted months \n",
    "#    RETURNS DataFrame of all the ETCs within the wanted season\n",
    "def get_season(m1, m2, m3) :\n",
    "    return df24.loc[((df24.datetime//10000)%100 == m1) \n",
    "                    | ((df24.datetime//10000)%100 == m2) \n",
    "                    | ((df24.datetime//10000)%100 == m3)]\n",
    "\n",
    "jja = get_season(6,7,8)\n",
    "son = get_season(9,10,11)\n",
    "djf = get_season(12,1,2)\n",
    "mam = get_season(3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "literary-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv files for each season\n",
    "\n",
    "djf.to_csv('/pampa/cloutier/etc_24_nna_djf.csv', index = False)\n",
    "mam.to_csv('/pampa/cloutier/etc_24_nna_mam.csv', index = False)\n",
    "jja.to_csv('/pampa/cloutier/etc_24_nna_jja.csv', index = False)\n",
    "son.to_csv('/pampa/cloutier/etc_24_nna_son.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-indiana",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
