{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "labeled-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "further-soviet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# open catalogue dataset\n",
    "df = pd.read_csv('/home/data/ReAnalysis/ERA5/Storm_analysis/NAECv1/NAEC_1979_2020_v1.csv')\n",
    "\n",
    "# open catalogue that contains storm that were active for more than 24h\n",
    "# more in CRCM6 domain\n",
    "df24 = pd.read_csv('/pampa/cloutier/etc_24_nna.csv')\n",
    "\n",
    "# open netcdf mask file\n",
    "file = '/pampa/picart/Masks/mask_GEM5_ERA5grid'\n",
    "data = xr.open_dataset(file)\n",
    "\n",
    "# export netcdf to dataframe\n",
    "mask = data.to_dataframe()\n",
    "\n",
    "# drop index lat lon, but keep columns\n",
    "mask = mask.reset_index()\n",
    "\n",
    "# keep in mask values where HU = true\n",
    "maskT = mask.loc[mask.HU != False]\n",
    "\n",
    "# open catalogue that contains storm that were active for more than 24h in CRCM domain \n",
    "# for each season\n",
    "djf = pd.read_csv('/pampa/cloutier/etc_24_nna_djf.csv')\n",
    "mam = pd.read_csv('/pampa/cloutier/etc_24_nna_mam.csv')\n",
    "jja = pd.read_csv('/pampa/cloutier/etc_24_nna_jja.csv')\n",
    "son = pd.read_csv('/pampa/cloutier/etc_24_nna_son.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-fashion",
   "metadata": {},
   "source": [
    "### Count tracks within 250km of grid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "derived-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using only the grid points that are within the CRCM6 domain as a test\n",
    "\n",
    "ec = pd.merge(df24, maskT) # ec = era5 and cr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-poster",
   "metadata": {},
   "source": [
    "### Storm track density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-crown",
   "metadata": {},
   "source": [
    "### density (test) PREND TROP DE TEMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "compound-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy.spatial import cKDTree\n",
    "\n",
    "# # Set the radius in kilometers\n",
    "# radius_km = 250\n",
    "\n",
    "# # Convert radius to degrees (approximation)\n",
    "# radius_deg = radius_km / 111.2\n",
    "\n",
    "# # Create a copy of the DataFrame with only relevant columns\n",
    "# son_copy = son[['latitude', 'longitude', 'storm']].copy()\n",
    "\n",
    "# # Initialize the storm density column with zeros\n",
    "# son_copy['storm_density'] = 0\n",
    "\n",
    "# # Convert latitude and longitude to radians for distance calculation\n",
    "# son_copy['lat_rad'] = np.radians(son_copy['latitude'])\n",
    "# son_copy['lon_rad'] = np.radians(son_copy['longitude'])\n",
    "\n",
    "# # Create a KDTree for efficient nearest neighbor search\n",
    "# tree = cKDTree(son_copy[['lat_rad', 'lon_rad']])\n",
    "\n",
    "# #Iterate over each grid point\n",
    "# for index, row in son_copy.iterrows():\n",
    "#     lat_rad = row['lat_rad']\n",
    "#     lon_rad = row['lon_rad']\n",
    "    \n",
    "    \n",
    "#     # Query the KDTree for grid points within the radius\n",
    "#     neighbors = tree.query_ball_point([lat_rad, lon_rad], radius_deg)\n",
    "    \n",
    "#     # Filter out grid points related to the same storm\n",
    "#     neighbors = [n for n in neighbors if son_copy.loc[son_copy.index[n], 'storm'] != row['storm']]\n",
    "    \n",
    "#     # Update the storm density for the current grid point\n",
    "#     son_copy.loc[index, 'storm_density'] = len(neighbors)\n",
    "    \n",
    "\n",
    "# # Save the resulting DataFrame to a CSV file\n",
    "# son_copy[['latitude', 'longitude', 'storm_density']].to_csv('/pampa/cloutier/storm_density.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-andorra",
   "metadata": {},
   "source": [
    "### Storm track density for son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transsexual-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate distance between two points using Haversine formula\n",
    "# Haversine package ?\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    # Earth radius in kilometers\n",
    "    earth_radius = 6371\n",
    "\n",
    "    # Convert latitude and longitude to radians\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "\n",
    "    # Calculate differences\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # Calculate distance in kilometers\n",
    "    distance = earth_radius * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store track density SON\n",
    "track_density = {}\n",
    "\n",
    "# Iterate through each storm track\n",
    "for i in range(len(son)):\n",
    "    storm_id = son.iloc[i]['storm']\n",
    "    lat = son.iloc[i]['latitude']\n",
    "    lon = son.iloc[i]['longitude']\n",
    "    \n",
    "    # Check if storm track has already been counted. If so, ignore and go to next\n",
    "    if storm_id in track_density:\n",
    "        continue\n",
    "    \n",
    "    # Initialize track density for current storm track\n",
    "    density = 0\n",
    "    \n",
    "    # Iterate through all grid points\n",
    "    for j in range(len(son)):\n",
    "        if i != j:\n",
    "            lat2 = son.iloc[j]['latitude']\n",
    "            lon2 = son.iloc[j]['longitude']\n",
    "            distance = calculate_distance(lat, lon, lat2, lon2)\n",
    "\n",
    "            if distance <= 250:\n",
    "                density += 1\n",
    "    \n",
    "    # Store track density for current storm track\n",
    "    track_density[storm_id] = density\n",
    "\n",
    "# Create a new dataset with latitude, longitude, and track density\n",
    "density_data = pd.DataFrame(columns=['Latitude', 'Longitude', 'Track Density'])\n",
    "\n",
    "# Iterate through unique storm IDs and corresponding grid points\n",
    "for storm_id, grid_point in track_density.items():\n",
    "    lat, lon = grid_point\n",
    "    density_data = density_data.append({'Latitude': lat, 'Longitude': lon, 'Track Density': track_density[storm_id]}, ignore_index=True)\n",
    "\n",
    "#create csv file \n",
    "density_data.to_csv('/pampa/cloutier/density_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-burns",
   "metadata": {},
   "source": [
    "### Storm track density for djf mam and jja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store track density SON\n",
    "track_density = {}\n",
    "\n",
    "# Iterate through each season\n",
    "for month in (djf, mam, jja) :\n",
    "    \n",
    "    # Iterate through each storm track\n",
    "    for i in range(len(month)):\n",
    "        storm_id = month.iloc[i]['storm']\n",
    "        lat = month.iloc[i]['latitude']\n",
    "        lon = month.iloc[i]['longitude']\n",
    "    \n",
    "        # Check if storm track has already been counted. If so, ignore and go to next\n",
    "        if storm_id in track_density:\n",
    "            continue\n",
    "    \n",
    "        # Initialize track density for current storm track\n",
    "        density = 0\n",
    "    \n",
    "        # Iterate through all grid points\n",
    "        for j in range(len(month)):\n",
    "            if i != j:\n",
    "                lat2 = month.iloc[j]['latitude']\n",
    "                lon2 = month.iloc[j]['longitude']\n",
    "                distance = calculate_distance(lat, lon, lat2, lon2)\n",
    "\n",
    "                if distance <= 250:\n",
    "                    density += 1\n",
    "    \n",
    "        # Store track density for current storm track\n",
    "        track_density[storm_id] = density\n",
    "\n",
    "    # Create a new dataset with latitude, longitude, and track density\n",
    "    density_data = pd.DataFrame(columns=['Latitude', 'Longitude', 'Track Density'])\n",
    "\n",
    "    # Iterate through unique storm IDs and corresponding grid points\n",
    "    for storm_id, grid_point in track_density.items():\n",
    "        lat, lon = grid_point\n",
    "        density_data = density_data.append({'Latitude': lat, 'Longitude': lon, 'Track Density': track_density[storm_id]}, ignore_index=True)\n",
    "\n",
    "    #create csv file \n",
    "    density_data.to_csv('/pampa/cloutier/density_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
